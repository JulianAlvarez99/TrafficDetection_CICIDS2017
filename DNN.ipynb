{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gE3w3CagW-ab",
        "outputId": "aa08b9df-2bc2-4a12-9f25-e3292f3b4407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_model_optimization\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow_model_optimization) (1.4.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow_model_optimization) (0.1.9)\n",
            "Collecting numpy~=1.23 (from tensorflow_model_optimization)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six~=1.14 in /usr/local/lib/python3.11/dist-packages (from tensorflow_model_optimization) (1.17.0)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow_model_optimization) (25.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from dm-tree~=0.1.1->tensorflow_model_optimization) (1.17.2)\n",
            "Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, tensorflow_model_optimization\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 tensorflow_model_optimization-0.8.0\n"
          ]
        }
      ],
      "source": [
        "#!pip install imblearn\n",
        "!pip install tensorflow_model_optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFpRo6FKyhvn"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade pandas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBO7vRQ_UuCm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# Configurar para evitar errores de memoria en GPU (si aplica)\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "def load_cicids2017(data_dir):\n",
        "    # Buscar todos los CSVs en el directorio\n",
        "    csv_files = glob.glob(os.path.join(data_dir, '*.csv'))\n",
        "    if not csv_files:\n",
        "        raise FileNotFoundError(\"No se encontraron archivos CSV en el directorio especificado.\")\n",
        "\n",
        "    # Cargar y concatenar todos los CSVs\n",
        "    dfs = [pd.read_csv(f, encoding='utf-8', low_memory=False) for f in csv_files]\n",
        "    data = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "    # Limpiar nombres de columnas (algunas tienen espacios)\n",
        "    data.columns = data.columns.str.strip()\n",
        "\n",
        "    # Manejar valores infinitos y NaN\n",
        "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "    data.dropna(inplace=True)\n",
        "\n",
        "    # Separar características y etiquetas\n",
        "    X = data.drop('Label', axis=1)\n",
        "    y = data['Label']\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def preprocess_data(X, y):\n",
        "    # Codificar etiquetas\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "    # Guardar mapeo de clases\n",
        "    class_mapping = dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))\n",
        "    print(\"Mapeo de clases:\", class_mapping)\n",
        "\n",
        "    # Escalar características\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Dividir en train/test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        "    )\n",
        "\n",
        "    # Aplicar SMOTE para balancear clases en el conjunto de entrenamiento\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    return X_train_bal, X_test, y_train_bal, y_test, label_encoder\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJrI3bYAVKkT"
      },
      "outputs": [],
      "source": [
        "# 2. Definir el modelo DNN base\n",
        "def create_dnn_model(input_dim, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43-smmv0VQTa"
      },
      "outputs": [],
      "source": [
        "# 3. Definir modelo profesor para Knowledge Distillation\n",
        "def create_teacher_model(input_dim, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Dense(256, activation='relu', input_shape=(input_dim,)),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dropout(0.4),\n",
        "        layers.Dense(32, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGrmVCoIVTgy"
      },
      "outputs": [],
      "source": [
        "# 4. Clase para Knowledge Distillation\n",
        "class DistillationModel(tf.keras.Model):\n",
        "    def __init__(self, student, teacher, alpha=0.1, temperature=3.0):\n",
        "        super(DistillationModel, self).__init__()\n",
        "        self.student = student\n",
        "        self.teacher = teacher\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def compile(self, optimizer, metrics, student_loss_fn, distillation_loss_fn):\n",
        "        super(DistillationModel, self).compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "        teacher_predictions = self.teacher(x, training=False)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            student_predictions = self.student(x, training=True)\n",
        "            student_loss = self.student_loss_fn(y, student_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(\n",
        "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
        "                tf.nn.softmax(student_predictions / self.temperature, axis=1)\n",
        "            )\n",
        "            total_loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
        "\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(total_loss, trainable_vars)\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hktm8Ie7VWYv"
      },
      "outputs": [],
      "source": [
        "# 5. Entrenar y evaluar modelo\n",
        "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name, epochs=10, batch_size=128):\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_split=0.2,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluar\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"\\n{model_name} - Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "    # Predicciones detalladas\n",
        "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "    print(f\"\\nClassification Report - {model_name}:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbXhwCHbVZ1D"
      },
      "outputs": [],
      "source": [
        "# 6. Aplicar QAT\n",
        "def apply_qat(model):\n",
        "    qat_model = tfmot.quantization.keras.quantize_model(model)\n",
        "    qat_model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return qat_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW0AwddJoBB7",
        "outputId": "816b1217-3215-43f4-edaa-1ff656ba5f7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/dhoogla/cicids2017?dataset_version_number=3...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 227M/227M [00:01<00:00, 189MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"dhoogla/cicids2017\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq504VktoK3f",
        "outputId": "7224c6ab-2035-42ab-a0f2-d23f2282857a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/Benign-Monday-no-metadata.parquet\n",
            "/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/DoS-Wednesday-no-metadata.parquet\n",
            "/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/Bruteforce-Tuesday-no-metadata.parquet\n",
            "/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/Infiltration-Thursday-no-metadata.parquet\n",
            "/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/Botnet-Friday-no-metadata.parquet\n",
            "/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/WebAttacks-Thursday-no-metadata.parquet\n",
            "/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/Portscan-Friday-no-metadata.parquet\n",
            "/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/DDoS-Friday-no-metadata.parquet\n"
          ]
        }
      ],
      "source": [
        "for dirname, _, filenames in os.walk('/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byxNtKp5oTXy"
      },
      "outputs": [],
      "source": [
        "df_data_1 = pd.read_parquet('/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/Benign-Monday-no-metadata.parquet')\n",
        "df_data_2 = pd.read_parquet('/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/Botnet-Friday-no-metadata.parquet')\n",
        "#df_data_3 = pd.read_parquet('/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/Bruteforce-Tuesday-no-metadata.parquet')\n",
        "df_data_4 = pd.read_parquet('/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/DDoS-Friday-no-metadata.parquet')\n",
        "#df_data_5 = pd.read_parquet('/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/DoS-Wednesday-no-metadata.parquet')\n",
        "df_data_6 = pd.read_parquet('/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/Infiltration-Thursday-no-metadata.parquet')\n",
        "#df_data_7 = pd.read_parquet('/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/Portscan-Friday-no-metadata.parquet')\n",
        "df_data_8 = pd.read_parquet('/root/.cache/kagglehub/datasets/dhoogla/cicids2017/versions/3/WebAttacks-Thursday-no-metadata.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOU3i1i0puaj"
      },
      "outputs": [],
      "source": [
        "df_data = pd.concat([df_data_1, df_data_2, df_data_4,\n",
        "                     df_data_6, df_data_8], axis=0, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6nScr9hpz0m"
      },
      "outputs": [],
      "source": [
        " # Limpiar nombres de columnas (algunas tienen espacios)\n",
        "df_data.columns = df_data.columns.str.strip()\n",
        "\n",
        "# Manejar valores infinitos y NaN\n",
        "df_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df_data.dropna(inplace=True)\n",
        "\n",
        "# Separar características y etiquetas\n",
        "X = df_data.drop('Label', axis=1)\n",
        "y = df_data['Label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLiWWTdxqOuG",
        "outputId": "982c5b87-1972-4bc9-a182-142df24ba92a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocesando datos...\n",
            "Mapeo de clases: {'Benign': 0, 'Bot': 1, 'DDoS': 2, 'Infiltration': 3, 'Web Attack � Brute Force': 4, 'Web Attack � Sql Injection': 5, 'Web Attack � XSS': 6}\n",
            "Dimensiones de entrada: 77, Número de clases: 7\n"
          ]
        }
      ],
      "source": [
        "  # Preprocesar\n",
        "  print(\"Preprocesando datos...\")\n",
        "  X_train, X_test, y_train, y_test, label_encoder = preprocess_data(X, y)\n",
        "  input_dim = X_train.shape[1]\n",
        "  num_classes = len(label_encoder.classes_)\n",
        "  print(f\"Dimensiones de entrada: {input_dim}, Número de clases: {num_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "IfLCIH3X1HsR",
        "outputId": "a565f617-8741-4b74-df62-9948f949ef3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entrenando modelo base...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m9,984\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m231\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,984</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,551\u001b[0m (80.28 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,551</span> (80.28 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,551\u001b[0m (80.28 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,551</span> (80.28 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "  # 7. Entrenar modelo base\n",
        "  print(\"\\nEntrenando modelo base...\")\n",
        "  base_model = create_dnn_model(input_dim, num_classes)\n",
        "  base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  base_history = train_and_evaluate(\n",
        "      base_model, X_train, y_train, X_test, y_test, \"Modelo Base\"\n",
        "  )"
      ],
      "metadata": {
        "id": "okxf3PH_Fzuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "fRVxjDv5GCjc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8KPlFEh5EMl"
      },
      "outputs": [],
      "source": [
        "  # Guardar tamaño del modelo base\n",
        "  base_model.save('C:/Users/Adrian/Desktop/JulianFacu/base_model.h5')\n",
        "  base_size = os.path.getsize('base_model.h5') / (1024 * 1024)  # MB\n",
        "  print(f\"Tamaño del modelo base: {base_size:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSKeF-m05G3p"
      },
      "outputs": [],
      "source": [
        "  # 8. Entrenar modelo con QAT\n",
        "  print(\"\\nEntrenando modelo con QAT...\")\n",
        "  qat_model = apply_qat(base_model)\n",
        "  qat_history = train_and_evaluate(\n",
        "      qat_model, X_train, y_train, X_test, y_test, \"Modelo QAT\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6E4Utm75NyS"
      },
      "outputs": [],
      "source": [
        "  # Convertir a TFLite para medir tamaño\n",
        "  qat_model.save('C:/Users/Adrian/Desktop/JulianFacu/base_model.h5')\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(qat_model)\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  tflite_model = converter.convert()\n",
        "  with open('qat_model.tflite', 'wb') as f:\n",
        "      f.write(tflite_model)\n",
        "  qat_size = os.path.getsize('qat_model.tflite') / (1024 * 1024)  # MB\n",
        "  print(f\"Tamaño del modelo QAT: {qat_size:.2f} MB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR6sERZe5Qp9"
      },
      "outputs": [],
      "source": [
        "  # 9. Entrenar modelo con Knowledge Distillation\n",
        "  print(\"\\nEntrenando modelo profesor...\")\n",
        "  teacher_model = create_teacher_model(input_dim, num_classes)\n",
        "  teacher_model.fit(\n",
        "      X_train, y_train,\n",
        "      validation_split=0.2,\n",
        "      epochs=10,\n",
        "      batch_size=64,\n",
        "      verbose=1\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOcSoUj95Wda"
      },
      "outputs": [],
      "source": [
        "  print(\"\\nAplicando Knowledge Distillation...\")\n",
        "  student_model = create_dnn_model(input_dim, num_classes)\n",
        "  distiller = DistillationModel(\n",
        "      student=student_model,\n",
        "      teacher=teacher_model,\n",
        "      alpha=0.1,\n",
        "      temperature=3.0\n",
        "  )\n",
        "  distiller.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        "      student_loss_fn=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      distillation_loss_fn=tf.keras.losses.KLDivergence()\n",
        "  )\n",
        "  distillation_history = train_and_evaluate(\n",
        "      distiller, X_train, y_train, X_test, y_test, \"Modelo Destilado\"\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Qkr4i0W5XcQ"
      },
      "outputs": [],
      "source": [
        "  # Guardar tamaño del modelo destilado\n",
        "  student_model.save('C:/Users/Adrian/Desktop/JulianFacu/student_model.h5')\n",
        "  student_size = os.path.getsize('student_model.h5') / (1024 * 1024)  # MB\n",
        "  print(f\"Tamaño del modelo destilado: {student_size:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6NKrhilVdmq"
      },
      "outputs": [],
      "source": [
        "  # 10. Resumen de resultados\n",
        "  print(\"\\nResumen de tamaños:\")\n",
        "  print(f\"Modelo Base: {base_size:.2f} MB\")\n",
        "  print(f\"Modelo QAT: {qat_size:.2f} MB\")\n",
        "  print(f\"Modelo Destilado: {student_size:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSELWf87XbUW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}